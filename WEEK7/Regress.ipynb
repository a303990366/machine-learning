{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_diabetes().data,load_diabetes().target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_train: 2812.369,test: 3108.041\n",
      "R2_train: 0.530,test: 0.459\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "#print(lr.coef_)#迴歸係數\n",
    "\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "\n",
    "print('MSE_train: %.3f,test: %.3f' % (mean_squared_error(y_train,y_train_pred),\n",
    "                                     mean_squared_error(y_test,y_test_pred)))\n",
    "print('R2_train: %.3f,test: %.3f' % (r2_score(y_train,y_train_pred),\n",
    "                                     r2_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#當其他預測因子存在時，特定預測因子的強度即為迴歸係數\n",
    "#註:\n",
    "    #1.要小心共線性(共線性:由於變量之間存在高度相關關係，而使回歸的預測不準確)\n",
    "    #2.X要先標準化\n",
    "#如何解決共線性?:\n",
    "#     1.資料預處理\n",
    "#         1-1.資料轉換\n",
    "#         1-2.挑選獨立變數\n",
    "#     2.脊回歸\n",
    "#     3.主成分分析(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_train: 0.522,test: 0.473\n",
      "R2_train: 0.433,test: 0.433\n",
      "R2_train: 0.151,test: 0.162\n"
     ]
    }
   ],
   "source": [
    "#脊回歸\n",
    "from sklearn.linear_model import Ridge\n",
    "for i in [0.1,1,10]:\n",
    "    ridge=Ridge(alpha=i).fit(X_train,y_train)\n",
    "    #alpha為正則化參數，過大會造成欠擬合;反之，會造成過擬合\n",
    "    #print(ridge.coef_)\n",
    "    y_train_pred=ridge.predict(X_train)\n",
    "    y_test_pred=ridge.predict(X_test)\n",
    "\n",
    "    print('R2_train: %.3f,test: %.3f' % (r2_score(y_train,y_train_pred),\n",
    "                                         r2_score(y_test,y_test_pred)))\n",
    "\n",
    "#複雜度越低的模型在訓練集上表現越差，但泛化能力較好\n",
    "#如果注重模型泛化的能力應該選擇ridge而非線性回歸\n",
    "#模型越好=>r2接近1\n",
    "#若test的r2_score大於train的r2_score為過擬合\n",
    "#若test的mse小於train的mse為過擬合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_train: 0.530,test: 0.460\n",
      "R2_train: 0.519,test: 0.480\n",
      "R2_train: 0.362,test: 0.366\n"
     ]
    }
   ],
   "source": [
    "#LASSO 回歸\n",
    "from sklearn.linear_model import Lasso\n",
    "for i in [0.001,0.1,1]:\n",
    "    lasso=Lasso(alpha=i).fit(X_train,y_train)\n",
    "    #print(lasso.coef_)#某些係數變為0\n",
    "    y_train_pred=lasso.predict(X_train)\n",
    "    y_test_pred=lasso.predict(X_test)\n",
    "\n",
    "    print('R2_train: %.3f,test: %.3f' % (r2_score(y_train,y_train_pred),\n",
    "                                         r2_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#小結:\n",
    "#     1.如果資料特徵太多並且只有少部分特徵是重要的，選擇LASSO較佳\n",
    "#     ，而且也較好解釋\n",
    "#     2.實作時，ridge為首選，因為LASSO選擇少數特徵時，會犧牲掉模型的正確性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_train: 0.517,test: 0.476\n",
      "R2_train: 0.379,test: 0.389\n",
      "R2_train: 0.009,test: 0.008\n",
      "R2_train: 0.000,test: -0.001\n"
     ]
    }
   ],
   "source": [
    "#彈性網\n",
    "#結合脊回歸與LASSO回歸\n",
    "from sklearn.linear_model import ElasticNet\n",
    "for i in [0.001,0.01,1,10]:\n",
    "    net=ElasticNet(alpha=i,l1_ratio=0.5).fit(X_train,y_train)\n",
    "#l1_ratio==1時，就變成LASSO模型\n",
    "    y_train_pred=net.predict(X_train)\n",
    "    y_test_pred=net.predict(X_test)\n",
    "\n",
    "    print('R2_train: %.3f,test: %.3f' % (r2_score(y_train,y_train_pred),\n",
    "                                         r2_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料來源:\n",
    "#     1.https://blog.csdn.net/hzw19920329/article/details/77200475\n",
    "#     2.共線性-維基百科\n",
    "#     3.東吳大學機器學習導論-regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
